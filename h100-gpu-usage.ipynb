{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"sourceType":"competition"},{"sourceId":14162644,"sourceType":"datasetVersion","datasetId":9027166},{"sourceId":673630,"sourceType":"modelInstanceVersion","modelInstanceId":510517,"modelId":525201}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nfrom IPython.display import clear_output\n!pip install transformers accelerate peft bitsandbytes datasets GPUtil trl\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:24:26.515833Z","iopub.execute_input":"2025-12-15T13:24:26.516065Z","iopub.status.idle":"2025-12-15T13:24:28.834411Z","shell.execute_reply.started":"2025-12-15T13:24:26.516048Z","shell.execute_reply":"2025-12-15T13:24:28.833922Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install scikit-learn\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:23:01.254332Z","iopub.execute_input":"2025-12-15T13:23:01.254562Z","iopub.status.idle":"2025-12-15T13:23:03.361905Z","shell.execute_reply.started":"2025-12-15T13:23:01.254541Z","shell.execute_reply":"2025-12-15T13:23:03.361460Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Dataset preparation","metadata":{}},{"cell_type":"code","source":"import json\n\nfile_path = \"/kaggle/input/interview-questions/interview_questions.jsonl\"\n\ndata = []\nwith open(file_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        data.append(json.loads(line))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:23:06.899080Z","iopub.execute_input":"2025-12-15T13:23:06.899291Z","iopub.status.idle":"2025-12-15T13:23:06.920463Z","shell.execute_reply.started":"2025-12-15T13:23:06.899274Z","shell.execute_reply":"2025-12-15T13:23:06.920053Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import random\nfrom datasets import Dataset, DatasetDict\n\ndef format_prompt(example):\n    \"\"\"Format in Llama instruction format\"\"\"\n    prompt = f\"\"\"<s>[INST] {example['instruction']} [/INST] {example['output']}</s>\"\"\"\n    return {\"text\": prompt}\n\nformatted_data = [format_prompt(item) for item in data]\n\nrandom.shuffle(formatted_data)\nsplit_idx = int(len(formatted_data) * 0.9)\ntrain_data = formatted_data[:split_idx]\nval_data = formatted_data[split_idx:]\n\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\n    \ndataset_dict = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:23:11.462936Z","iopub.execute_input":"2025-12-15T13:23:11.463153Z","iopub.status.idle":"2025-12-15T13:23:16.290649Z","shell.execute_reply.started":"2025-12-15T13:23:11.463139Z","shell.execute_reply":"2025-12-15T13:23:16.290233Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_path = \"/kaggle/input/llama3-2/pytorch/default/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_path,\n    use_fast = True\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize_function(examples):\n    result = tokenizer(\n        examples['text'],\n        truncation=True,\n        max_length=512,\n        padding='max_length'\n    )\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result\n\ntokenized_datasets = dataset_dict.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=dataset_dict['train'].column_names\n    )\n    \nprint(f\"Train examples: {len(tokenized_datasets['train'])}\")\nprint(f\"Validation examples: {len(tokenized_datasets['validation'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:50:09.647493Z","iopub.execute_input":"2025-12-15T13:50:09.648052Z","iopub.status.idle":"2025-12-15T13:50:10.397597Z","shell.execute_reply.started":"2025-12-15T13:50:09.648038Z","shell.execute_reply":"2025-12-15T13:50:10.397198Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/811 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bcbb2d33354ae28205e1e5aa4ebaae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/91 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875a5c32c9c94d1e97a06906dc28958a"}},"metadata":{}},{"name":"stdout","text":"Train examples: 811\nValidation examples: 91\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### LoRa Fine-Tuning","metadata":{}},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    BitsAndBytesConfig,\n    DataCollatorForLanguageModeling\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    prepare_model_for_kbit_training\n)\nfrom trl import SFTTrainer\n\nOUTPUT_DIR = \"kaggle/working/lora_llama3_3b\"\n\nMAX_SEQ_LEN = 2048\nBATCH_SIZE = 2\nGRAD_ACCUM = 8\nEPOCHS = 3\nLR = 2e-4\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    dtype=torch.bfloat16\n)\n\nmodel = prepare_model_for_kbit_training(model)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\"\n    ],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T14:07:47.181387Z","iopub.execute_input":"2025-12-15T14:07:47.181591Z","iopub.status.idle":"2025-12-15T14:07:51.931291Z","shell.execute_reply.started":"2025-12-15T14:07:47.181579Z","shell.execute_reply":"2025-12-15T14:07:51.930810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69c2b3f4f32c456da66c73dad4e23036"}},"metadata":{}},{"name":"stdout","text":"trainable params: 9,175,040 || all params: 3,221,924,864 || trainable%: 0.2848\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install -U trl transformers peft accelerate\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T14:04:11.980305Z","iopub.execute_input":"2025-12-15T14:04:11.980951Z","iopub.status.idle":"2025-12-15T14:04:15.016041Z","shell.execute_reply.started":"2025-12-15T14:04:11.980924Z","shell.execute_reply":"2025-12-15T14:04:15.015572Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    per_device_train_batch_size=BATCH_SIZE,\n    gradient_accumulation_steps=GRAD_ACCUM,\n    num_train_epochs=EPOCHS,\n    learning_rate=LR,\n    warmup_ratio=0.05,\n    lr_scheduler_type=\"cosine\",\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    bf16=True,\n    tf32=True,\n    gradient_checkpointing=True,\n    optim=\"paged_adamw_32bit\",\n    report_to=\"none\",\n    max_grad_norm=1.0,\n    run_name=\"lora_llama3.2_h100\"\n)\n\ndata_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer,\n        mlm=False\n    )\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    args=training_args,\n    data_collator = data_collator\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T14:07:54.972097Z","iopub.execute_input":"2025-12-15T14:07:54.972565Z","iopub.status.idle":"2025-12-15T14:12:34.417956Z","shell.execute_reply.started":"2025-12-15T14:07:54.972552Z","shell.execute_reply":"2025-12-15T14:12:34.417540Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/811 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de760daf0b7649448c3493460f06656a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/91 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3ae77546e924e27bab387e5f61b1b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='153' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [153/153 04:35, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>3.309600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.103300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.757100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.695300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.571700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.453000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.367300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.374500</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.325800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.268500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.098100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.109800</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.055500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.080300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.077300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=153, training_loss=1.5011901699639614, metrics={'train_runtime': 278.6596, 'train_samples_per_second': 8.731, 'train_steps_per_second': 0.549, 'total_flos': 2.113638997111603e+16, 'train_loss': 1.5011901699639614, 'entropy': 0.5288935886187986, 'num_tokens': 1245696.0, 'mean_token_accuracy': 0.7602718445387754, 'epoch': 3.0})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}